{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAP07IJ4Wihl"
   },
   "source": [
    "# Hate Intensity Prediction (HIP): Regression\n",
    "\n",
    "HIP Module takes a sentence (whether normalised or not) and predicts the hateful intensity of the sentence.\n",
    "\n",
    "The hate intensity is annotated on a scale of 1-10, 0 is reserved for non-hateful sentences which we do not use in our dataset.\n",
    "1 is the lowest hate intensity and 10 is the highest.\n",
    "\n",
    "If using final activation layer is linear then range stays same.\n",
    "If using sigmoid activation layer then input label is normalised to 0-1 range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "CyY42zwliaTy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\research\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DistilBertTokenizer, RobertaTokenizer, BertConfig, TFBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.spatial import distance\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# Limit GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dcG8YhvdWihs"
   },
   "outputs": [],
   "source": [
    "BASE_FOLDER = \"../dataset/\"\n",
    "INPUT_FILE = \"hate_norm_combined.pkl\"\n",
    "OUTPUT_FOLDER = \"hate_intensity_linear_weights_att/\"\n",
    "OUTPUT_FILE = \"hate_int_linear_trans42_ATT\"\n",
    "BERT_MODEL = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 128\n",
    "TEST_SIZE = 0.2\n",
    "SEED = 42\n",
    "\n",
    "USE_ATT = True\n",
    "\n",
    "BERT_DROPOUT = 0.2\n",
    "LSTM_UNITS = 50\n",
    "DENSE_UNITS = 50\n",
    "LSTM_DROPOUT = 0.1\n",
    "DENSE_DROPOUT = 0.2\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "def random_seed(SEED):\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "\n",
    "random_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk1pjHGJWiht"
   },
   "source": [
    "### Base TRANSFORMER MODEL definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "4a00d3a5e03e4ab39cef6d7cb6b681e2",
      "517c53f11cb54901915b8b5ff51ea1eb",
      "4fbc3f9b0b7746e3abe32e50caa476bd",
      "503c547d013149a6934a8deee64ff8d3",
      "77449a47f0344c99b43ed4cce9ecbbf2",
      "f6fa2a7f94de4da18576897e38b32524",
      "77fbc55d360441228b2fbcc30d931d3e",
      "ed1e81a603924c08a2d95e1a5076e192",
      "0bb77466a84c459584313438f70a7ceb",
      "e014073eacd442759a4921bc4f7f479e",
      "7cf656fa522349da9a8fe4c3fae0622e",
      "b8e122cf7001419eb14bf2978d4aca68",
      "02ca8c27663e4a20930808c9c2a90144",
      "ba156719d0f64f1fa4d46919346b51c1",
      "3474099f1950438282dbd56ba19787dc",
      "1f404fe3a05f434c945cdcfbaea2d776",
      "1c18db5697444b1cab0d75e00b55448a",
      "0a92b5ebf3dc458288c5e4d442a059cd",
      "b0a893bb19674c81bd7b53c8d9d326b5",
      "045b1575a1054f6fab1867248df47a9d",
      "794f8529e96247cab09091fe6b43c616",
      "5b14e6976a194de0b1cee96a85e29944"
     ]
    },
    "executionInfo": {
     "elapsed": 11189,
     "status": "ok",
     "timestamp": 1659508618143,
     "user": {
      "displayName": "Sarah Masud",
      "userId": "01097683761850841511"
     },
     "user_tz": -330
    },
    "id": "f6e63Pg2f0DQ",
    "outputId": "9f962c2b-f3ee-4573-d4a6-cdf8206ad5b8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\research\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'vocab_projector.bias', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'vocab_layer_norm.weight', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'vocab_transform.weight', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'vocab_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'vocab_transform.bias', 'distilbert.embeddings.word_embeddings.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def tokenize(sentences, tokenizer):\n",
    "    input_ids, input_masks, input_segments = [], [], []\n",
    "    for sentence in tqdm(sentences):\n",
    "        inputs = tokenizer.encode_plus(sentence,\n",
    "                                       add_special_tokens=True,\n",
    "                                       max_length=MAX_LENGTH,\n",
    "                                       pad_to_max_length=True,\n",
    "                                       return_attention_mask=True,\n",
    "                                       return_token_type_ids=True)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])\n",
    "\n",
    "    return np.asarray(input_ids, dtype='int32'), np.asarray(\n",
    "        input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n",
    "\n",
    "\n",
    "## Define base bert configs\n",
    "config = BertConfig(dropout=BERT_DROPOUT,\n",
    "                    attention_dropout=BERT_DROPOUT,\n",
    "                    output_attentions=True)\n",
    "config.output_hidden_states = False\n",
    "transformer_model = TFBertModel.from_pretrained(BERT_MODEL, config=config)\n",
    "for layer in transformer_model.layers[:3]:  ## We are freezing first 3 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Defining tokonizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL,\n",
    "                                                do_lower_case=True,\n",
    "                                                add_special_tokens=True,\n",
    "                                                max_length=MAX_LENGTH,\n",
    "                                                pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cb-cLfmWihu"
   },
   "source": [
    "### Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7026,
     "status": "ok",
     "timestamp": 1659508627945,
     "user": {
      "displayName": "Sarah Masud",
      "userId": "01097683761850841511"
     },
     "user_tz": -330
    },
    "id": "nGcE9_IkigmR",
    "outputId": "a7995095-db80-4d68-8021-5e0e663c854b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_token (InputLayer)       [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " masked_token (InputLayer)      [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_token[0][0]',            \n",
      "                                thPoolingAndCrossAt               'masked_token[0][0]']           \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=((N                                               \n",
      "                                one, 12, None, 128)                                               \n",
      "                                , (None, 12, None,                                                \n",
      "                                128),                                                             \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28),                                                              \n",
      "                                 (None, 12, None, 1                                               \n",
      "                                28)),                                                             \n",
      "                                 cross_attentions=N                                               \n",
      "                                one)                                                              \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 128, 100)     327600      ['tf_bert_model[0][12]']         \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, 128, 100)     1           ['bidirectional[0][0]',          \n",
      "                                                                  'bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 100)         0           ['attention[0][0]']              \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           5050        ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 50)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            51          ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,814,942\n",
      "Trainable params: 332,702\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ids_in = tf.keras.layers.Input(shape=(MAX_LENGTH, ),\n",
    "                                     name='input_token',\n",
    "                                     dtype='int32')\n",
    "input_masks_in = tf.keras.layers.Input(shape=(MAX_LENGTH, ),\n",
    "                                       name='masked_token',\n",
    "                                       dtype='int32')\n",
    "embedding_layer = transformer_model(input_ids_in,\n",
    "                                    attention_mask=input_masks_in)[0]\n",
    "X = tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(LSTM_UNITS,\n",
    "                         return_sequences=True,\n",
    "                         dropout=LSTM_DROPOUT,\n",
    "                         recurrent_dropout=LSTM_DROPOUT,\n",
    "                         kernel_initializer='normal'))(embedding_layer)\n",
    "if USE_ATT:\n",
    "    X = tf.keras.layers.Attention(use_scale=True)([X, X])  # Use attention.\n",
    "X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
    "X = tf.keras.layers.Dense(DENSE_UNITS,\n",
    "                          activation='relu',\n",
    "                          kernel_initializer='normal')(X)\n",
    "X = tf.keras.layers.Dropout(DENSE_DROPOUT)(X)\n",
    "X = tf.keras.layers.Dense(\n",
    "    1,\n",
    "    activation='linear',  # Can be with activation=\"sigmoid\" here.\n",
    "    kernel_initializer='normal')(X)\n",
    "model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs=X)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',  # Treat HIP as a regression problem\n",
    "    metrics=['acc', tf.keras.metrics.RootMeanSquaredError()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bugZ2DEOWihw"
   },
   "source": [
    "### Dataset prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5622,
     "status": "ok",
     "timestamp": 1659508638138,
     "user": {
      "displayName": "Sarah Masud",
      "userId": "01097683761850841511"
     },
     "user_tz": -330
    },
    "id": "Tkxwym01Wihw",
    "outputId": "03a1088b-4e07-4294-e6b5-71d3635222d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                         | 0/4843 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\anaconda3\\envs\\research\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████| 4843/4843 [00:02<00:00, 2307.83it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 1211/1211 [00:00<00:00, 2339.22it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(BASE_FOLDER + INPUT_FILE, 'rb') as f:\n",
    "    input_data = pickle.load(f)\n",
    "\n",
    "intensity_value = []\n",
    "hate_sentences = []\n",
    "\n",
    "for i in range(len(input_data)):\n",
    "    intensity_value.append(int(input_data['Original_Intensity'][i]))\n",
    "    hate_sentences.append(input_data['Sentence'][i])\n",
    "    intensity_value.append(int(input_data['Normalized_Intensity'][i]))\n",
    "    hate_sentences.append(input_data['Normalized_Sentence'][i])\n",
    "\n",
    "c = list(zip(intensity_value, hate_sentences))\n",
    "random.shuffle(c)\n",
    "intensity_value, hate_sentences = zip(*c)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(hate_sentences,\n",
    "                                          intensity_value,\n",
    "                                          test_size=TEST_SIZE,\n",
    "                                          random_state=1)\n",
    "\n",
    "train_input_ids, train_input_masks, train_input_segment = tokenize(\n",
    "    X_tr, tokenizer)\n",
    "test_input_ids, test_input_masks, test_input_segment = tokenize(\n",
    "    X_te, tokenizer)\n",
    "y_tr = np.asarray(y_tr)\n",
    "y_te = np.asarray(y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSRZbOhdWihw"
   },
   "source": [
    "### Train and evlauate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345275,
     "status": "ok",
     "timestamp": 1659508989014,
     "user": {
      "displayName": "Sarah Masud",
      "userId": "01097683761850841511"
     },
     "user_tz": -330
    },
    "id": "WDKVTxtQWihx",
    "outputId": "1fc8e2ca-c4b5-4b92-c8bb-9400026dcfe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "137/137 [==============================] - 222s 2s/step - loss: 7.2723 - acc: 0.0067 - root_mean_squared_error: 2.6967 - val_loss: 4.1728 - val_acc: 0.0062 - val_root_mean_squared_error: 2.0428\n",
      "Epoch 2/10\n",
      "137/137 [==============================] - 209s 2s/step - loss: 4.6334 - acc: 0.0067 - root_mean_squared_error: 2.1525 - val_loss: 3.9898 - val_acc: 0.0062 - val_root_mean_squared_error: 1.9974\n",
      "Epoch 3/10\n",
      "137/137 [==============================] - 211s 2s/step - loss: 4.1446 - acc: 0.0067 - root_mean_squared_error: 2.0358 - val_loss: 3.4245 - val_acc: 0.0062 - val_root_mean_squared_error: 1.8505\n",
      "Epoch 4/10\n",
      "137/137 [==============================] - 207s 2s/step - loss: 3.6845 - acc: 0.0067 - root_mean_squared_error: 1.9195 - val_loss: 3.1628 - val_acc: 0.0062 - val_root_mean_squared_error: 1.7784\n",
      "Epoch 5/10\n",
      "137/137 [==============================] - 215s 2s/step - loss: 3.5062 - acc: 0.0067 - root_mean_squared_error: 1.8725 - val_loss: 2.9579 - val_acc: 0.0062 - val_root_mean_squared_error: 1.7199\n",
      "Epoch 6/10\n",
      "137/137 [==============================] - 200s 1s/step - loss: 3.3299 - acc: 0.0067 - root_mean_squared_error: 1.8248 - val_loss: 2.8998 - val_acc: 0.0062 - val_root_mean_squared_error: 1.7029\n",
      "Epoch 7/10\n",
      "137/137 [==============================] - 201s 1s/step - loss: 3.0938 - acc: 0.0067 - root_mean_squared_error: 1.7589 - val_loss: 2.8504 - val_acc: 0.0062 - val_root_mean_squared_error: 1.6883\n",
      "Epoch 8/10\n",
      "137/137 [==============================] - 203s 1s/step - loss: 2.9927 - acc: 0.0067 - root_mean_squared_error: 1.7299 - val_loss: 2.2780 - val_acc: 0.0062 - val_root_mean_squared_error: 1.5093\n",
      "Epoch 9/10\n",
      "137/137 [==============================] - 200s 1s/step - loss: 2.8244 - acc: 0.0067 - root_mean_squared_error: 1.6806 - val_loss: 2.2313 - val_acc: 0.0062 - val_root_mean_squared_error: 1.4938\n",
      "Epoch 10/10\n",
      "137/137 [==============================] - 200s 1s/step - loss: 2.6431 - acc: 0.0067 - root_mean_squared_error: 1.6258 - val_loss: 2.1726 - val_acc: 0.0062 - val_root_mean_squared_error: 1.4740\n",
      "TEST split 0.2\n",
      "38/38 [==============================] - 15s 382ms/step - loss: 2.4399 - acc: 0.0058 - root_mean_squared_error: 1.5620\n",
      "[2.439889907836914, 0.005780346691608429, 1.5620146989822388]\n",
      "38/38 [==============================] - 17s 378ms/step\n",
      "pear PearsonRResult(statistic=0.6804587931742341, pvalue=1.9277905605316274e-165)\n",
      "cosine 0.9666823247718692\n"
     ]
    }
   ],
   "source": [
    "model.fit(x=[train_input_ids, train_input_masks],\n",
    "          y=y_tr,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.1,\n",
    "          batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"TEST split\", TEST_SIZE)\n",
    "results = model.evaluate(x=[test_input_ids, test_input_masks], y=y_te)\n",
    "print(results)\n",
    "result = model.predict(x=[test_input_ids, test_input_masks])\n",
    "result = np.array(result, dtype=np.float64)\n",
    "result = result.flatten()\n",
    "print(\"pear\", stats.pearsonr(result, y_te))\n",
    "print(\"cosine\", 1 - distance.cosine(result, y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Combine the features and labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m: X_tr, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensity\u001b[39m\u001b[38;5;124m'\u001b[39m: y_tr})\n\u001b[0;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m: X_te, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensity\u001b[39m\u001b[38;5;124m'\u001b[39m: y_te})\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine the features and labels\n",
    "train_data = pd.DataFrame({'sentence': X_tr, 'intensity': y_tr})\n",
    "test_data = pd.DataFrame({'sentence': X_te, 'intensity': y_te})\n",
    "\n",
    "# Save to CSV\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDhskIwCWvHh"
   },
   "source": [
    "### To save model\n",
    "Run\n",
    "```\n",
    "# model.save_weights(BASE_FOLDER + OUTPUT_FOLDER + OUTPUT_FILE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gouti7v7Wihx"
   },
   "source": [
    "### To load model\n",
    "Run upto the cells up till `model_design` part and then do\n",
    "```\n",
    "model.load_weights(BASE_FOLDER+OUTPUT_FOLDER+OUTPUT_FILE)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hate_intensity_prediction.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02ca8c27663e4a20930808c9c2a90144": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c18db5697444b1cab0d75e00b55448a",
      "placeholder": "​",
      "style": "IPY_MODEL_0a92b5ebf3dc458288c5e4d442a059cd",
      "value": "Downloading: 100%"
     }
    },
    "045b1575a1054f6fab1867248df47a9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a92b5ebf3dc458288c5e4d442a059cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0bb77466a84c459584313438f70a7ceb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c18db5697444b1cab0d75e00b55448a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f404fe3a05f434c945cdcfbaea2d776": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3474099f1950438282dbd56ba19787dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_794f8529e96247cab09091fe6b43c616",
      "placeholder": "​",
      "style": "IPY_MODEL_5b14e6976a194de0b1cee96a85e29944",
      "value": " 232k/232k [00:00&lt;00:00, 424kB/s]"
     }
    },
    "4a00d3a5e03e4ab39cef6d7cb6b681e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_517c53f11cb54901915b8b5ff51ea1eb",
       "IPY_MODEL_4fbc3f9b0b7746e3abe32e50caa476bd",
       "IPY_MODEL_503c547d013149a6934a8deee64ff8d3"
      ],
      "layout": "IPY_MODEL_77449a47f0344c99b43ed4cce9ecbbf2"
     }
    },
    "4fbc3f9b0b7746e3abe32e50caa476bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed1e81a603924c08a2d95e1a5076e192",
      "max": 363423424,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0bb77466a84c459584313438f70a7ceb",
      "value": 363423424
     }
    },
    "503c547d013149a6934a8deee64ff8d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e014073eacd442759a4921bc4f7f479e",
      "placeholder": "​",
      "style": "IPY_MODEL_7cf656fa522349da9a8fe4c3fae0622e",
      "value": " 363M/363M [00:06&lt;00:00, 53.6MB/s]"
     }
    },
    "517c53f11cb54901915b8b5ff51ea1eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f6fa2a7f94de4da18576897e38b32524",
      "placeholder": "​",
      "style": "IPY_MODEL_77fbc55d360441228b2fbcc30d931d3e",
      "value": "Downloading: 100%"
     }
    },
    "5b14e6976a194de0b1cee96a85e29944": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "77449a47f0344c99b43ed4cce9ecbbf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77fbc55d360441228b2fbcc30d931d3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "794f8529e96247cab09091fe6b43c616": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cf656fa522349da9a8fe4c3fae0622e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0a893bb19674c81bd7b53c8d9d326b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8e122cf7001419eb14bf2978d4aca68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02ca8c27663e4a20930808c9c2a90144",
       "IPY_MODEL_ba156719d0f64f1fa4d46919346b51c1",
       "IPY_MODEL_3474099f1950438282dbd56ba19787dc"
      ],
      "layout": "IPY_MODEL_1f404fe3a05f434c945cdcfbaea2d776"
     }
    },
    "ba156719d0f64f1fa4d46919346b51c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0a893bb19674c81bd7b53c8d9d326b5",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_045b1575a1054f6fab1867248df47a9d",
      "value": 231508
     }
    },
    "e014073eacd442759a4921bc4f7f479e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed1e81a603924c08a2d95e1a5076e192": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6fa2a7f94de4da18576897e38b32524": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
