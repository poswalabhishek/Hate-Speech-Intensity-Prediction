{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c21233d-6c23-4a47-948e-957b8d3ad61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the merged dataframe\n",
    "merged_df = pd.read_csv('merged_output.csv')\n",
    "\n",
    "# Extract the necessary columns\n",
    "ml_predictions = merged_df['Predicted_Intensity'].values\n",
    "gpt_predictions = merged_df['gpt_intensity'].values\n",
    "true_values = merged_df['intensity'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf7eacc5-a7dd-40b1-b835-a4e1988fa0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Averaging - RMSE: 0.9092646204400056, Pearson Correlation: 0.9002543655210911, Cosine Similarity: 0.9881170705343353\n",
      "Weighted Averaging - RMSE: 0.9331484406194158, Pearson Correlation: 0.8943887774887066, Cosine Similarity: 0.987452865681709\n",
      "Stacking - RMSE: 0.9064992969610338, Pearson Correlation: 0.9002769898783781, Cosine Similarity: 0.988139605860322\n"
     ]
    }
   ],
   "source": [
    "# Simple Averaging\n",
    "combined_predictions_avg = (ml_predictions + gpt_predictions) / 2\n",
    "\n",
    "# Weighted Averaging\n",
    "weight_ml = 0.7\n",
    "weight_gpt = 0.3\n",
    "combined_predictions_weighted = weight_ml * ml_predictions + weight_gpt * gpt_predictions\n",
    "\n",
    "# Evaluate the combined predictions\n",
    "def evaluate(predictions, true_values):\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predictions))\n",
    "    pearson_corr, _ = pearsonr(true_values, predictions)\n",
    "    cosine_sim = cosine_similarity([true_values], [predictions])[0, 0]\n",
    "    return rmse, pearson_corr, cosine_sim\n",
    "\n",
    "# Evaluate simple averaging\n",
    "rmse_avg, pearson_avg, cosine_avg = evaluate(combined_predictions_avg, true_values)\n",
    "print(f\"Simple Averaging - RMSE: {rmse_avg}, Pearson Correlation: {pearson_avg}, Cosine Similarity: {cosine_avg}\")\n",
    "\n",
    "# Evaluate weighted averaging\n",
    "rmse_weighted, pearson_weighted, cosine_weighted = evaluate(combined_predictions_weighted, true_values)\n",
    "print(f\"Weighted Averaging - RMSE: {rmse_weighted}, Pearson Correlation: {pearson_weighted}, Cosine Similarity: {cosine_weighted}\")\n",
    "\n",
    "# Stacking\n",
    "stacked_features = np.vstack((ml_predictions, gpt_predictions)).T\n",
    "stacked_model = LinearRegression().fit(stacked_features, true_values)\n",
    "stacked_predictions = stacked_model.predict(stacked_features)\n",
    "\n",
    "# Evaluate stacking\n",
    "rmse_stacked, pearson_stacked, cosine_stacked = evaluate(stacked_predictions, true_values)\n",
    "print(f\"Stacking - RMSE: {rmse_stacked}, Pearson Correlation: {pearson_stacked}, Cosine Similarity: {cosine_stacked}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e321d22a-0bf4-4517-abad-7edf681517b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b93da2-e2b3-449c-883f-80e42fc76c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the CSV file\n",
    "file_path = 'merged_output.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the necessary columns\n",
    "outputgpt = data['gpt_intensity'].values\n",
    "outputroberta = data['Original_Predicted_Intensity'].values\n",
    "groundtruth = data['intensity'].values\n",
    "\n",
    "# Normalize the inputs\n",
    "scaler = StandardScaler()\n",
    "outputgpt = scaler.fit_transform(outputgpt.reshape(-1, 1))\n",
    "outputroberta = scaler.fit_transform(outputroberta.reshape(-1, 1))\n",
    "groundtruth = scaler.fit_transform(groundtruth.reshape(-1, 1))\n",
    "\n",
    "class CombineModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombineModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.w = nn.Parameter(torch.randn(1, requires_grad=True))\n",
    "        \n",
    "    def forward(self, outputgpt, outputroberta):\n",
    "        sigmoid_w = torch.sigmoid(self.w)\n",
    "        outputinterm = sigmoid_w * outputgpt + (1 - sigmoid_w) * outputroberta\n",
    "        outputinterm = torch.relu(self.fc1(outputinterm))\n",
    "        outputinterm = self.dropout(outputinterm)\n",
    "        outputinterm = torch.relu(self.fc2(outputinterm))\n",
    "        outputinterm = self.dropout(outputinterm)\n",
    "        outputinterm = self.fc3(outputinterm)\n",
    "        return outputinterm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461f94a8-53a0-45cd-99c2-a66c06cf1ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\envs\\research\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.2197\n",
      "Epoch [200/1000], Loss: 0.2111\n",
      "Epoch [300/1000], Loss: 0.2095\n",
      "Epoch [400/1000], Loss: 0.2065\n",
      "Epoch [500/1000], Loss: 0.2049\n",
      "Epoch [600/1000], Loss: 0.2045\n",
      "Epoch [700/1000], Loss: 0.2036\n",
      "Epoch [800/1000], Loss: 0.2023\n",
      "Epoch [900/1000], Loss: 0.2029\n",
      "Epoch [1000/1000], Loss: 0.2008\n",
      "RMSE: 0.8943\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for training\n",
    "outputgpt_tensor = torch.tensor(outputgpt, dtype=torch.float32)\n",
    "outputroberta_tensor = torch.tensor(outputroberta, dtype=torch.float32)\n",
    "groundtruth_tensor = torch.tensor(groundtruth, dtype=torch.float32)\n",
    "\n",
    "# Instantiate the model, define the loss function and the optimizer\n",
    "model = CombineModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(outputgpt_tensor, outputroberta_tensor)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, groundtruth_tensor)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted = model(outputgpt_tensor, outputroberta_tensor).numpy()\n",
    "\n",
    "# Inverse transform the predicted values to their original scale\n",
    "predicted = scaler.inverse_transform(predicted)\n",
    "groundtruth = scaler.inverse_transform(groundtruth)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(mean_squared_error(groundtruth, predicted))\n",
    "print(f'RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea588d-97c1-4160-a7b8-24c9aee873f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
