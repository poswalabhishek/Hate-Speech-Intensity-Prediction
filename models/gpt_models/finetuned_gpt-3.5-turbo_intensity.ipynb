{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c0791c-d600-48d4-afb8-306b1aa8ea31",
   "metadata": {},
   "source": [
    "### Fine-tuning and training Azure GPT 3.5 Turbo model to produce an intensity on a scale of 1 to 10. \n",
    "\n",
    "Link: https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/fine-tuning?tabs=turbo%2Cpython-new&pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c176636d-5204-4930-87f0-7f7db8e22ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from helper import new_azure_credentials, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6203dc99-2707-436a-bab8-68d4503d83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key= new_azure_credentials['api_key'],  \n",
    "    api_version= new_azure_credentials['api_version'],\n",
    "    azure_endpoint = new_azure_credentials['azure_endpoint']\n",
    "    )\n",
    "\n",
    "#This will correspond to the custom name you chose for your deployment when you deployed a model. Use a gpt-35-turbo-instruct deployment. \n",
    "deployment_name='gpt-35-turbo' \n",
    "datasets_path = paths['datasets_path']\n",
    "json_datasets_path = paths['json_datasets_path']\n",
    "\n",
    "data = pd.read_csv(datasets_path + 'hate_int_prof_SVO.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68ac706-852f-45c7-8fb6-6d785e50b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to convert DataFrame to JSONL format for GPT-3.5 Turbo\n",
    "def convert_to_jsonl(data, file_path):\n",
    "    jsonl_data = []\n",
    "    for index, row in data.iterrows():\n",
    "        jsonl_data.append({\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a linguistic researcher specializing in evaluating the intensity of hate speech in sentences. Your task is to rate the intensity on a scale from 1 to 10, where 1 represents minimal hate speech and 10 represents extreme hate speech. This evaluation is crucial for creating a dataset that researchers can utilize to filter and understand harmful content effectively.\"},\n",
    "                {\"role\": \"user\", \"content\": row['Sentence']},\n",
    "                {\"role\": \"assistant\", \"content\": str(row['Intensity'])}\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    with open(file_path, 'w') as outfile:\n",
    "        for entry in jsonl_data:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "convert_to_jsonl(train_data, json_datasets_path + 'gpt_training_set.jsonl')\n",
    "convert_to_jsonl(val_data, json_datasets_path + 'gpt_validation_set.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a4bf06-b000-41f1-b091-db7c81893283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training file ID: file-44cf10a0f7a94763b16e0573ab410756\n",
      "Validation file ID: file-ccdaec573fa14af6b06152b222541fbf\n"
     ]
    }
   ],
   "source": [
    "training_file_name = json_datasets_path + 'gpt_training_set.jsonl'\n",
    "validation_file_name = json_datasets_path + 'gpt_validation_set.jsonl'\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI with the SDK.\n",
    "training_response = client.files.create(\n",
    "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "training_file_id = training_response.id\n",
    "\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_name, \"rb\"), purpose=\"fine-tune\"\n",
    ")\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(\"Training file ID:\", training_file_id)\n",
    "print(\"Validation file ID:\", validation_file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7e8042-bc56-4143-8c85-a21d78cb336a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-0e61ba8ff38c41aeb885f64928004295\n",
      "Status: pending\n",
      "{\n",
      "  \"id\": \"ftjob-0e61ba8ff38c41aeb885f64928004295\",\n",
      "  \"created_at\": 1718179628,\n",
      "  \"error\": null,\n",
      "  \"fine_tuned_model\": null,\n",
      "  \"finished_at\": null,\n",
      "  \"hyperparameters\": {\n",
      "    \"n_epochs\": -1,\n",
      "    \"batch_size\": -1,\n",
      "    \"learning_rate_multiplier\": 1\n",
      "  },\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"object\": \"fine_tuning.job\",\n",
      "  \"organization_id\": null,\n",
      "  \"result_files\": null,\n",
      "  \"seed\": null,\n",
      "  \"status\": \"pending\",\n",
      "  \"trained_tokens\": null,\n",
      "  \"training_file\": \"file-44cf10a0f7a94763b16e0573ab410756\",\n",
      "  \"validation_file\": \"file-ccdaec573fa14af6b06152b222541fbf\",\n",
      "  \"estimated_finish\": null,\n",
      "  \"integrations\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(\n",
    "    training_file=training_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-4-0613\",\n",
    "    # hypperparameters={}\n",
    ")\n",
    "\n",
    "job_id = response.id\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tuning job.\n",
    "# The fine-tuning job will take some time to start and complete.\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "112e01d7-6c66-440c-808c-8c1b3b62835c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-0e61ba8ff38c41aeb885f64928004295', created_at=1718179628, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=-1, batch_size=-1, learning_rate_multiplier=1), model='gpt-4-0613', object='fine_tuning.job', organization_id=None, result_files=None, seed=None, status='pending', trained_tokens=None, training_file='file-44cf10a0f7a94763b16e0573ab410756', validation_file='file-ccdaec573fa14af6b06152b222541fbf', estimated_finish=None, integrations=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380cbd9d-48c3-49c5-b9f2-d91d1053c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: pending\n"
     ]
    }
   ],
   "source": [
    "print(\"Status:\", response.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea049057-43d8-4127-808f-d52fc6d46a87",
   "metadata": {},
   "source": [
    "### To get a token, go to Azure portal and in the CLI, run the following command:\n",
    "\n",
    "```az account get-access-token```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5be0f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new deployment...\n",
      "<Response [201]>\n",
      "Created\n",
      "{'id': '/subscriptions/4e05894f-dae4-4e4c-9213-f2a81f019b24/resourceGroups/research/providers/Microsoft.CognitiveServices/accounts/research-gpt/deployments/gpt-35-turbo-ft', 'type': 'Microsoft.CognitiveServices/accounts/deployments', 'name': 'gpt-35-turbo-ft', 'sku': {'name': 'standard', 'capacity': 1}, 'properties': {'model': {'format': 'OpenAI', 'name': 'gpt-35-turbo-0125.ft-1cedaf4241954b63bd1b7ebd1cc2370b', 'version': '1'}, 'versionUpgradeOption': 'NoAutoUpgrade', 'currentCapacity': 1, 'capabilities': {'chatCompletion': 'true'}, 'provisioningState': 'Creating', 'rateLimits': [{'key': 'request', 'renewalPeriod': 10, 'count': 1}, {'key': 'token', 'renewalPeriod': 60, 'count': 1000}]}, 'systemData': {'createdBy': 'microsoft@efadrin.com', 'createdByType': 'User', 'createdAt': '2024-06-06T15:53:16.6215901Z', 'lastModifiedBy': 'microsoft@efadrin.com', 'lastModifiedByType': 'User', 'lastModifiedAt': '2024-06-06T15:53:16.6215901Z'}, 'etag': '\"b11f5568-fd27-4c93-b34d-1cd0807df386\"'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "token= \"eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkwxS2ZLRklfam5YYndXYzIyeFp4dzFzVUhIMCIsImtpZCI6IkwxS2ZLRklfam5YYndXYzIyeFp4dzFzVUhIMCJ9.eyJhdWQiOiJodHRwczovL21hbmFnZW1lbnQuY29yZS53aW5kb3dzLm5ldC8iLCJpc3MiOiJodHRwczovL3N0cy53aW5kb3dzLm5ldC9mYjY1NjUwNC04ODI5LTQ0OTAtOGUzOC0yZTQwZDM3OTA4ZGEvIiwiaWF0IjoxNzE3Njg3OTgzLCJuYmYiOjE3MTc2ODc5ODMsImV4cCI6MTcxNzY5Mjg1MiwiYWNyIjoiMSIsImFpbyI6IkFXUUFtLzhXQUFBQXVvb2tReHZySk5UUzExT1JrK1NPVUZKTWt3NEhqSmxWWWJvRE1IczZqNS9rSE5lKzV3QVhCK3VVczZSYUVvUmpIWjdnVHlWeTNNTXVGWENxTk5valpKcXRZVkhCZkdmUUZraENrR2pldnFGSWxqVTA1WDZYdlIxaXJxVmFWWG5LIiwiYWx0c2VjaWQiOiIxOmxpdmUuY29tOjAwMDMwMDAwNzhEQkU3MDQiLCJhbXIiOlsicHdkIl0sImFwcGlkIjoiYjY3N2MyOTAtY2Y0Yi00YThlLWE2MGUtOTFiYTY1MGE0YWJlIiwiYXBwaWRhY3IiOiIwIiwiZW1haWwiOiJtaWNyb3NvZnRAZWZhZHJpbi5jb20iLCJmYW1pbHlfbmFtZSI6IkdhbmRoaSIsImdpdmVuX25hbWUiOiJNYWhhdG1hIiwiZ3JvdXBzIjpbImVhNTI1NDgxLTM1YzAtNDY3Ni1iY2M0LWE5MTQ4MmE3MDEzYSJdLCJpZHAiOiJsaXZlLmNvbSIsImlkdHlwIjoidXNlciIsImlwYWRkciI6IjEwMy4xNjMuMjIwLjIzNSIsIm5hbWUiOiJNYWhhdG1hIEdhbmRoaSIsIm9pZCI6ImIyODg5ODhjLWFmNmUtNDM1ZC04MzRhLWUzYmU3OTI1Yjk1ZCIsInB1aWQiOiIxMDAzMjAwMzhENzY5QTA1IiwicmgiOiIwLkFiNEFCR1ZsLXltSWtFU09PQzVBMDNrSTJrWklmM2tBdXRkUHVrUGF3ZmoyTUJPLUFIWS4iLCJzY3AiOiJ1c2VyX2ltcGVyc29uYXRpb24iLCJzdWIiOiJqcG45XzNwSUpjbk1YWjhnc1IxbnVGTElWRUIwWnJoRkFsZHRud01DVVlJIiwidGlkIjoiZmI2NTY1MDQtODgyOS00NDkwLThlMzgtMmU0MGQzNzkwOGRhIiwidW5pcXVlX25hbWUiOiJsaXZlLmNvbSNtaWNyb3NvZnRAZWZhZHJpbi5jb20iLCJ1dGkiOiJpYi1vb3ZlXzcwV0txYTdxUTdwbkFBIiwidmVyIjoiMS4wIiwid2lkcyI6WyI2MmU5MDM5NC02OWY1LTQyMzctOTE5MC0wMTIxNzcxNDVlMTAiLCJiNzlmYmY0ZC0zZWY5LTQ2ODktODE0My03NmIxOTRlODU1MDkiXSwieG1zX2Vkb3YiOnRydWUsInhtc190Y2R0IjoxNzE3NDk0NTkzfQ.hsgkP7PM_jg6yhHZi4oB5XWYU-MXzDiAwgyGdg6wYSbwIUXpxoSEh7iJzgRGzGKbAk7v9a7tb2dEVzwBMzbX3QQQz1KCUTfJ3C6rKIEMM-nz2ZTBLB2-2RzL5MwPcA61TPzuU8E6LhGvGaSpsF81Ske6xJ8PcjJ4cIVaTNxySA261zXY-aoInb917VxhmnxFIkWZF716J0cvhww0p7FKfSsCq591K2mM-cwt-pLZNPt9v6VnTYgX6GMPHj7M2_yZt_JFGb3XoSV6ATNKWKZQP2_V975UE1fWhGqJcGpVIZnPpBo27Bt17v17P6vY9bEn14pHXcQLyZd-o6Kbysd9mg\"\n",
    "subscription = \"4e05894f-dae4-4e4c-9213-f2a81f019b24\"  \n",
    "resource_group = \"research\"\n",
    "resource_name = \"research-gpt\"\n",
    "model_deployment_name =\"gpt-35-turbo-ft\" # custom deployment name that you will use to reference the model when making inference calls.\n",
    "\n",
    "deploy_params = {'api-version': \"2024-04-01-preview\"} \n",
    "deploy_headers = {'Authorization': 'Bearer {}'.format(token), 'Content-Type': 'application/json'}\n",
    "\n",
    "deploy_data = {\n",
    "    \"sku\": {\"name\": \"standard\", \"capacity\": 1}, \n",
    "    \"properties\": {\n",
    "        \"model\": {\n",
    "            \"format\": \"OpenAI\",\n",
    "            \"name\": \"gpt-35-turbo-0125.ft-1cedaf4241954b63bd1b7ebd1cc2370b\", #retrieve this value from the previous call, it will look like gpt-35-turbo-0613.ft-b044a9d3cf9c4228b5d393567f693b83\n",
    "            \"version\": \"1\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "deploy_data = json.dumps(deploy_data)\n",
    "\n",
    "request_url = f'https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resource_group}/providers/Microsoft.CognitiveServices/accounts/{resource_name}/deployments/{model_deployment_name}'\n",
    "\n",
    "print('Creating a new deployment...')\n",
    "\n",
    "r = requests.put(request_url, params=deploy_params, headers=deploy_headers, data=deploy_data)\n",
    "\n",
    "print(r)\n",
    "print(r.reason)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b093d49-f212-4a02-85c2-94be10b5036c",
   "metadata": {},
   "source": [
    "### Using a custom deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50aed5c9-52e9-4ada-bf47-89eda249af28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "content = \"Not good news at all but this happens in all European nations and is no doubt pushed by the likes of Jews like Summer Redstone and MTV ! !\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-35-turbo-ft\", # model = \"Custom deployment name you chose for your fine-tuning model\"\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a linguistic researcher specializing in evaluating the intensity of hate speech in sentences. Your task is to rate the intensity on a scale from 1 to 10, where 1 represents minimal hate speech and 10 represents extreme hate speech. This evaluation is crucial for creating a dataset that researchers can utilize to filter and understand harmful content effectively.\"}, \n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df1302-3b53-4259-958c-e017148b2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the file ID of the first result file from the fine-tuning job\n",
    "# for the customized model.\n",
    "response = client.fine_tuning.jobs.retrieve(job_id)\n",
    "if response.status == 'succeeded':\n",
    "    result_file_id = response.result_files[0]\n",
    "\n",
    "retrieve = client.files.retrieve(result_file_id)\n",
    "\n",
    "# Download the result file.\n",
    "print(f'Downloading result file: {result_file_id}')\n",
    "\n",
    "with open(retrieve.filename, \"wb\") as file:\n",
    "    result = client.files.content(result_file_id).read()\n",
    "    file.write(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
